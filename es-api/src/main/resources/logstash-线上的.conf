input {
    jdbc {
        jdbc_connection_string => "jdbc:mysql://mysql.gmdev.baiwang-inner.com:3306/seal_manager_dev?useUnicode=true&allowMultiQuerie=true&characterEncoding=utf-8&serverTimezone=UTC"
        jdbc_user => "root"
        jdbc_password => "123456"
        jdbc_driver_library => "/usr/local/logstash-7.12.0/my/mysql-connector-java-8.0.19.jar"
        jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
        jdbc_paging_enabled => true
        jdbc_page_size => "1000"
        jdbc_default_timezone =>"Asia/Shanghai"
        statement_filepath => "/usr/local/logstash-7.12.0/my/my.sql"
        schedule => "* * * * *"
        use_column_value => true
        last_run_metadata_path => "/usr/local/logstash-7.12.0/my/last_id"
        tracking_column => "id"
        tracking_column_type => "numeric"
        record_last_run => true
        clean_run => false
        lowercase_column_names => false
    }
}

#过滤、格式化数据
filter{
    mutate  {
        #将不需要的JSON字段过滤，且不会被存入 ES 中，@timestamp、@version 无用字段可删除
        remove_field => ["@version"]
    }
}

output {
    elasticsearch {
        hosts => ["10.100.4.10:9200","10.100.4.10:9201"]
        # 同步的索引名必须要有@timestamp  不然yyyyMM不起效
        index => "ps_sign_log%{+yyyyMM}"
        document_id => "%{id}"
        template_name => "ps_seal_log"
        template => "/usr/local/logstash-7.12.0/my/ps_seal_log_template.json"
        template_overwrite => true
    }
    stdout {
        codec => json_lines
    }
}
